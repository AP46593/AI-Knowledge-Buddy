# === Ollama model configuration ===
OLLAMA_CHAT_MODEL=llama3:8B
OLLAMA_EMBED_MODEL=nomic-embed-text:latest
#OLLAMA_VISION_MODEL=llava:13b  
OLLAMA_VISION_MODEL=llama3.2-vision:11b

# === Chunking ===
CHUNK_SIZE=1000
CHUNK_OVERLAP=400

# === Retrieval ===
TOP_K_RESULTS=10
TOP_P=0.9
MAX_TOKEN=1000
LOW_TOKEN=512
TEMPERATURE=0.4
LOW_TEMP=0.2
HIGH_TEMP=0.7
MEM_LIMIT=10

# === Data paths ===
INDEX_DIR=data/index

# === Streamlit config ===
STREAMLIT_TITLE=Knowledge & Incident Copilot